\section{Introduction}
\label{sec:intro}

Non Negative Matrix Factorization (NMF) is a widely used rank reduction method. The goal of NMF is to approximate a data matrix $V \in \mathbb{R}_{+}^{n \times m} $ as $V \approx \tilde{V} = WH$ with $W \in \mathbb{R}_{+}^{n \times k}$, $H \in \mathbb{R}_{+}^{k \times m}$, $k$ being the rank of factorization typically chosen such that \mbox{$k(n+m) << nm  $}~\cite{lee99}. As the data matrix $V$ is usually redundant, the product $WH$ can be thought as a compressed form of $V$. In audio signal processing, the input data is usually a Time-Frequency (TF) representation such as a short time Fourier transform (STFT) or a constant-Q transform spectrogram. The matrix $W$ is a {\em dictionary} or a set of {\em patterns} that codes the frequency information of the data. $H$ is the {\em activation matrix} and contains the {\em expansion coefficients} that code the temporal information.
This decomposition technique has been applied with great success in various audio signal processing tasks such as automatic transcription~\cite{EwertM12,NB:ICASSP-07}, audio source separation~\cite{HennequinDAFx2010,JLD:TASLP10}, multi-pitch estimation~\cite{raczynski2007multipitch} and music instruments recognition~\cite{cichocki2009nonnegative}.

Numerous schemes have been proposed in the NMF framework in the context of audio source separation. In the case where the signals are composed of many sources, the plain NMF does not give satisfying results and it is often necessary to rely, for instance, on supervised algorithms that exploit training data or prior information in order to guide the decomposition process. Also, information from the scores or from midi signals~\cite{EwertM12} can be used to initialize the learning process. The downside of this approach is that it requires a well organized prior information that is not always available. Another approach consists in performing prior training on specific databases. A dictionary matrix $W_{train}$ can be learned from a large database in order to separate an instrument~\cite{jaureguiberry2011adaptation,wudrum}. A common method to build a dictionary for NMF is to perform a decomposition on a large training set. After the convergence, the $W$ matrix from the decomposition is used as the dictionary matrix $W_{train}$ in the separation~\cite{jaureguiberry2011adaptation}. Another method is detailed in~\cite{wudrum}, where a dictionary matrix is created by extracting template spectra from isolated drum samples. The dictionary is then used in a NMF decomposition to perform drum transcription. This method requires minimum tuning from the user. However, the dictionary should match the target instrument for satisfying performances. 

On the other hand, unsupervised algorithms rely on parametric physical models of the instruments and they count on specific constraints deduced from the characteristics of the processed signals in order to perform the decomposition. For example, harmonic instruments tend to have regular activations and are slowly varying over time so enforcing temporal smoothness improves the physical meaning of the decomposition~\cite{Virtanen}. Similarly in~\cite{canadas2014percussive}, Canadas \& al. use four constraints to achieve a specific harmonic/percussive decomposition. The main drawback of parametrized methods is that the hyper parameters are difficult to tune, especially if the model is composed of numerous parameters. 

Concurrently, other unsupervised methods aim at underlining some mathematical properties of the decomposition, like the orthogonality between the nonnegative basis functions (or patterns). Projective NMF (PNMF) and orthogonal NMF (ONMF) are typical examples of such approaches. PNMF has been used with success in image processing~\cite{choi} for feature extraction and clustering~\cite{YangOja10}. It reveals interesting properties in practice: a higher efficiency for clustering than NMF~\cite{choi} and the generation of a much sparser decomposition than NMF~\cite{YangOja10}. These inherent properties are particularly interesting for audio source separation as shown in~\cite{canadas2014percussive,vincent2010adaptive}. 
The main advantage of these approaches compared to other unsupervised methods is that sparsity or orthogonality are obtained as intrinsic properties, so they avoid a tedious and often unsatisfactory hyperparameter tuning stage. However, these approaches do not have a sufficient flexibility to properly represent the complexity of an audio scene composed of multiple and concurrent harmonic and percussive sources.


%Finally some methods use a so-called semi-supervised algorithm where data from scores helps the constrained decomposition method~\cite{hennequin2011score,fritsch2013score} %{\MK Je pense que ce paragraphe peut √™tre supprim√©: il n'en dit pas assez, et je ne suis pas s√ªr qu'il soit n√©cessaire de d√©velopper. Ou alors, il faut l'int√©grer au paragraphe suivant qui parle de technique semi-supervis√©e. Mais la, il me parait un peu esseul\'e.} {\HP OK pour l'intégrer à la suite. Definir méthode semi-supervisee, citer comme exemple celles [15,16] et dire pourquoi celle proposée rentre dans cette categorie.}


In this article, we propose a semi-supervised decomposition technique suitable for harmonic/percussive source separation of non vocal monophonic instrumental signals. The method takes advantage of the sparse decomposition of PNMF but allows a better representation of complex audio signals. More precisely, the initial nearly-orthogonal decomposition obtained by PNMF is extended by non-orthogonal components that prove to be particularly relevant to represent percussive or transient signals. The sparse and orthogonal components of PNMF are prone to extract the harmonic instruments well localized in frequency, while the percussive part with flat spectra are extracted by the NMF components. However, as shown in~\cite{laroche2015structured} this direct approach obtains limited performances in a blind source separation task. To force the non-orthogonal components to extract the drum signal, we use a dictionary specific to drum signals using the same technique as in~\cite{wudrum}.
%The merit of this new method termed \textit{Structured Projected Nonnegative Matrix Factorization (SPNMF)} is experimentally demonstrated on synthetic signals and on a specific task of percussive/harmonic source separation of real audio signals. It has several characteristics which make it stand apart from previous work. Firstly the method is easy to tune as it has few parameters. Secondly it is robust to the wide variety of audio signal and perform well on genre specific signal. The main contributions of this article are :
%\begin{description}
%\item[$\bullet$ ] A comparison between different two training methods to establish the best drum dictionary.
%\item[$\bullet$ ] A Benchmark against three state of the art harmonic/percussive methods on a large database.
%\end{description}
%{\MK dans les contributions, il faut mettre la m√©thode SPNMF en elle-meme. Meme si elle apparait deja dans Eusipco. C'est le coeur de l'article. Je mettrais un truc du genre (√† d√©velopper):
The contributions of this article are threefold
\begin{enumerate}
\item The SPNMF method is introduced, as well as a simple multiplicative algorithm to solve the SPNMF problem.
\item  We offer a comparison between different two training methods to establish the best drum dictionary.
\item We perform a benchmark against three state of the art harmonic/percussive methods on a large database.	
\end{enumerate}

%}

The paper is organized as follows. In Section~\ref{sec:Background}, we describe the problem of harmonic/percussive source separation and we explain in details some recent state-of-the-art methods. The proposed SPNMF is then introduced in Section~\ref{sec:SPNMF}. We present our experimental protocol and the results obtained on synthetic and real audio signals in Section~\ref{sec:experiments}. Section~\ref{sec:stateoftheart} is a benchmark with state of the art methods. Finally, some conclusions are drawn in Section~\ref{sec:conc}.

