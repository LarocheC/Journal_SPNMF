\section{Context of harmonic/percussive decomposition}
\label{sec:Background}

%{\HP Introduire les deux classes d'instruments (harmonic/percussive) avant de détailler les instruments harmoniques.}
Harmonic/percussive source separation is based on the observation that harmonic instruments are tonal sounds very localized in frequency that can be modeled by a sum of sinusoidal waves and percussive instruments are wide band transient signals.

Harmonic instruments can be classified into several categories such as for example struck string instruments (piano, harpsichord, \ldots), plucked string instruments (guitar, mandolin, \ldots) or brass instruments (trumpet, tuba, \ldots)~\cite{peeters2003automatic}. These instruments can be modeled as a sum of three components: the Sinusoidal part, the Transients and the Residual, so called  Sines + Transients + Noise (STN) models~\cite{daudet2006review}. The transient of the harmonic instruments show some percussive properties (i.e., fast attack and fast decay). Taking into account the transient part of harmonic instruments is a challenging task that will not be treated this article. Here, as in other article of the literature, we rely on the hypothesis that most of the energy of the harmonic signal is in the tonal part. 

Harmonic/percussive source separation has numerous applications as a preprocessing step. For example most multi-pitch estimation models~\cite{klapuri2008multipitch}, instruments recognition~\cite{eronen2000musical} and melody extraction~\cite{salamon2012melody} algorithms are much more efficient if the influence of the percussive sources is diminished. Indeed, these algorithms often rely on the analysis of the harmonic structures that are blurred by the percussive instruments. Similarly, beat tracking~\cite{ellis2007beat} and drum transcription algorithms~\cite{paulus2005drum} are more accurate if the harmonic instruments are not part of the signal. Finally, using the Harmonic/Percussive Source Separation (HPSS) algorithm~\cite{fitzgerald2010harmonic} as a preprocessing step increases the performance for singing pitch extraction and voice separation~\cite{hsu2012tandem}. This has motivated the development of methods for HPSS in the music signal processing area. Numerous other methods exist but in this work, we will focus on three methods that are particularly relevant to our benchmark. 

%{\HP This has motivated the development of mettons for harmonic/percussive sound separation in the music signal processing area. \bold{remarque: } Il y a de nombreuses approches pour l'HPSS qui existent mais seulement 3 sont choisies ici, et ce choix a l'air arbitraire. Il faut dire (en deux mots) qu'il y en a beaucoup d'approches (on peut par exemple une classification recente comme celle de l'article de Tachibana et al. de 2014 ``Harmonic/Percussive Sound Separation Based on Anisotropic Smoothness of Spectrograms''). Ensuite dire qu'on se concentre ici sur 3 methodes pour les raisons suivantes : \cite{ono2008separation} parce qu'elle est simple et populaire, \cite{canadas2014percussive} parce qu'elle est a l'oppose de celle qu'on présente, avec beaucoup d'hyperparametres et \cite{kim2011nonnegative} parce qu'il y a une similarite d'idee avec l'approche presentee. Bref, retravailler un peu cette deuxieme partie de la Section II.}

A well known unsupervised method to extract the harmonic/percussive components consists in applying a Median Filtering (MF) on the spectrogram of the audio signal~\cite{fitzgerald2010harmonic}. The filtering is made across the temporal atoms to diminish the transient sounds in order to extract the harmonic components. Mutually, the filtering is made across frequency to reduce the harmonic tonal sounds and to enhance the percussive instruments. The assumption made is that the harmonics are considered to be outliers in a temporal frame that contains a mixture of percussive and pitched instruments. Similarly, the percussive onsets are considered to be outliers in a frequency frame. This method is often used in the \emph{Music Information Retrieval} community as it does not require any parameter tuning and is computationally effective. However, on a small scale test conducted by~\cite{canadas2014percussive}, this simple approach does not give the best separation results.% {\HP dans quell contexte? par rapport à quoi? Quels signaux de test ? }.

Another unsupervised method uses a NMF decomposition with specific constraints to distinguish the harmonic part from the percussive components~\cite{canadas2014percussive}. A simple approximation is that percussive instruments are transient sounds with regular spectra (wide band signals) whereas harmonic instruments are tonal sounds with harmonic sparse spectra. From this observation, a frequency regularity and a temporal sparsity constraints are applied during the optimization process to extract the percussive instruments and vice-versa a temporal regularity and a frequency sparsity constraints are applied to extract the harmonic instruments. Let consider the magnitude spectrogram $V$ composed of $T$ frames, $F$ frequency bins, the model is written as follow:
$$ V_{FT} \approx V_p + V_H = W_{P_{F,R_p}} H_{P_{F,R_p}} + W_{H_{F,R_h}} H_{H_{F,R_h}} $$
were the parameter $R_h$ and $R_p$ denote the number of harmonic and percussive components respectively. The harmonic sounds are modelled by assuming smoothness in time and sparseness in frequency. The Temporal Smoothness (TSM) is defined as follow 
\begin{equation}
TSM = \frac{F}{R_h} \sum_{r_h=1}^{R_h}\frac{1}{\sigma_{H_{H_{r_h}}}^2} \sum_{t=2}^{T}(H_{H_{r_h,t-1}} - H_{H_{r_h,t}})^2
\end{equation}
The value $\sigma_{H_{H}} = \sqrt{\frac{1}{T} \sum_{t=1}^{T} H_{H_{r_h,t}}^2 }$ is a normalization term to make the global objective function independent to the norm of the signal. Spectral Sparseness (SSP) is designed using the same constrain as in \cite{Virtanen}:
\begin{equation}
SSP = \frac{T}{R_h} \sum_{r_h=1}^{R_h}\sum_{f=1}^{F} \mid\frac{W_{H_{f,r_h}}}{\sigma_{W_{H_{r_h}}}}\mid
\end{equation}
with $\sigma = \sqrt{\frac{1}{F} \sum_{f=1}^{F} W_{H_{f,r_h}}^2 }$.
Similarly, for the percussive part, the authors used a constrain of Temporal Sparseness (TSP) on the activation matrix, and a constrain of Spectral Smoothness (SSM) on the dictionary matrix. 
This method gives good results compared to other state-of-the-art methods but this article will show that the results depend heavily on the training database.

Finally in~\cite{kim2011nonnegative}, a drum source separation is done using a Non-Negative Matrix Partial Co-Factorization (NMPCF). The spectrogram of the signal and the drum-only data (obtained from prior learning) are simultaneously decomposed in order to determine common basis vectors that capture the spectral and temporal characteristics of drum sources. The shared dictionary matrix retrieves the drum signal. However it must be chosen carefully in order to obtain satisfying results. The percussive part of the decomposition is constrained while the harmonic part is completely unconstrained. As a result, it tends to decompose a lot of information (i.e., the harmonic part contains some percussive instruments) from the signal and the decomposition is not satisfactory. In the NMPCF, the dictionary is not fixed. We will compare this method to the SPNMF were the dictionary is fixed. 
