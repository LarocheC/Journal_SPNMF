\section{Introduction}
\label{sec:intro}


Harmonic/percussive source separation (HPSS) is based on the observation that harmonic instruments are tonal sounds very localized in frequency that can be modelled by a sum of sinusoidal waves and percussive instruments are wide band transient signals.

Harmonic instruments can be classified into several categories such as for example struck string instruments (piano, harpsichord, \ldots), plucked string instruments (guitar, mandolin, \ldots) or brass instruments (trumpet, tuba, \ldots)~\cite{peeters2003automatic}. These instruments can be modeled as a sum of three components: the Sinusoidal part, the Transients and the Residual, so called  Sines + Transients + Noise (STN) models~\cite{daudet2006review}. The transient of the harmonic instruments show some percussive properties (i.e., fast attack and fast decay). Taking into account the transient part of harmonic instruments is a challenging task that will not be treated this article. Here, as in other article of the literature, we rely on the hypothesis that most of the energy of the harmonic signal is in the tonal part. 


HPSS has numerous applications as a preprocessing step. For example most multi-pitch estimation models~\cite{klapuri2008multipitch}, instruments recognition~\cite{eronen2000musical} and melody extraction~\cite{salamon2012melody,rigaudISMIR2016} algorithms are much more efficient on harmonic instruments alone. Indeed, these algorithms often rely on the analysis of the harmonic structures that are blurred by the percussive instruments. Similarly, drum transcription algorithms~\cite{paulus2005drum,wudrum2016} are more accurate if the harmonic instruments are not part of the signal. Finally, using the Median Filtering (MF) algorithm~\cite{fitzgerald2010harmonic} as a preprocessing step increases the performance for singing pitch extraction and voice separation~\cite{hsu2012tandem}. 


A well known unsupervised method to extract the harmonic/percussive components consists in applying a Median Filtering (MF) on the spectrogram of the audio signal~\cite{fitzgerald2010harmonic}. The filtering is made across the temporal atoms to diminish the transient sounds in order to extract the harmonic components. Mutually, the filtering is made across frequency to reduce the harmonic tonal sounds and to enhance the percussive instruments. The assumption made is that the harmonics are considered to be outliers in a temporal frame that contains a mixture of percussive and pitched instruments. Similarly, the percussive onsets are considered to be outliers in a frequency frame. This method is often used in the \emph{Music Information Retrieval} community as it does not require any parameter tuning and is computationally effective. However, this method does not perform well on non stationary signal such as tremolos or vibratos as these get divided between the harmonic and percussive part. 
% However, on a small scale test conducted by~\cite{canadas2014percussive}, this simple approach does not give the best separation results.

Another method for removing drums from a polyphonic audio signal consist in discarding time/frequency bins which present a percussive magnitude evolution, according to a pre-defined parametric model \cite{rigaud2011drum}. Special care is taken to reduce the irrelevant removal of frequency modulated signal such as the ones produced by the singing voice. This method provides competitive results compared to other state of the art methods but only in the case where the drum onset are clearly annotated. 

Other methods for source separation uses Non Negative Matrix Factorization (NMF). This method is a widely used rank reduction method. The goal of NMF is to approximate a data matrix $V \in \mathbb{R}_{+}^{n \times m} $ as $V \approx \tilde{V} = WH$ with $W \in \mathbb{R}_{+}^{n \times k}$, $H \in \mathbb{R}_{+}^{k \times m}$, $k$ being the rank of factorization typically chosen such that \mbox{$k(n+m) << nm  $}~\cite{lee99}. As the data matrix $V$ is usually redundant, the product $WH$ is a compressed form of $V$. In audio signal processing, the input data is usually a Time-Frequency (TF) representation such as a short time Fourier transform (STFT) or a constant-Q transform spectrogram. The matrix $W$ is a {\em dictionary} or a set of {\em patterns} that codes the frequency information of the data. $H$ is the {\em activation matrix} and contains the {\em expansion coefficients} that code the temporal information.

Another unsupervised method for HPSS uses a Non negative Matrix Factorization (NMF) decomposition with specific constraints (CoNMF) to distinguish the harmonic part from the percussive components~\cite{canadas2014percussive}. A simple approximation is that percussive instruments are transient sounds with regular spectra (wide band signals) whereas harmonic instruments are tonal sounds with harmonic sparse spectra. This method gives good results compared to other state-of-the-art methods but this article will show that it is not robust to the wide variety of audio signal as the results depend heavily on how the parameters are optimized during the training.

% In the NMPCF, the dictionary is not fixed. We will compare this method to the SPNMF were the dictionary is fixed. 

%This has motivated the development of methods for HPSS in the music signal processing area. We will focus on three methods that are particularly relevant to our benchmark. 

%Finally some methods use a so-called semi-supervised algorithm where data from scores helps the constrained decomposition method~\cite{hennequin2011score,fritsch2013score} %{\MK Je pense que ce paragraphe peut √™tre supprim√©: il n'en dit pas assez, et je ne suis pas s√ªr qu'il soit n√©cessaire de d√©velopper. Ou alors, il faut l'int√©grer au paragraphe suivant qui parle de technique semi-supervis√©e. Mais la, il me parait un peu esseul\'e.} {\HP OK pour l'intégrer à la suite. Definir méthode semi-supervisee, citer comme exemple celles [15,16] et dire pourquoi celle proposée rentre dans cette categorie.}


In this article, we propose a weakly-supervised decomposition technique suitable for harmonic/percussive source separation of non vocal monophonic instrumental signals in the NMF framework. The harmonic instruments well localized in frequency, are extracted by the sparse and orthogonal components, while the percussive part with flat spectra are extracted by regular components. Following the work first introduced in~\cite{laroche2015structured} we improve on this approach by forcing the non-orthogonal components to extract the drum signal. More precisely, we use a dictionary specific to drum signals using the same technique as in~\cite{wudrum}.

The contributions of this article are threefold
\begin{enumerate}
\item The Structured Projected Nonnegative Matrix Factorization (SPNMF) method is introduced, as well as a simple multiplicative algorithm to solve the SPNMF problem.
\item  We offer a comparison between two different training methods to establish the best drum dictionary.
\item We perform a benchmark against three state of the art harmonic/percussive methods on a large database.	
\end{enumerate}

The paper is organized as follows. In Section~\ref{sec:Background}, we present some recent work on NMF and we explain in details some recent state-of-the-art methods for HPSS. The proposed SPNMF is then introduced in Section~\ref{sec:SPNMF}. We present our experimental protocol and the results obtained on synthetic and real audio signals in Section~\ref{sec:experiments}. Section~\ref{sec:stateoftheart} is a benchmark with state of the art methods. Finally, some conclusions are drawn in Section~\ref{sec:conc}.


