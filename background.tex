\section{Related Work}
\label{sec:Background}


\subsection{Non Negative Matrix Factorization}

The NMF decomposition has been applied with great success in various audio signal processing tasks such as automatic transcription~\cite{EwertM12,NB:ICASSP-07}, audio source separation~\cite{HennequinDAFx2010,JLD:TASLP10}, multi-pitch estimation~\cite{raczynski2007multipitch} and music instruments recognition~\cite{cichocki2009nonnegative}.

In the case where the signals are composed of many sources, the plain NMF does not give satisfying results and it is often necessary to rely, for instance, on supervised algorithms that exploit training data or prior information in order to guide the decomposition process. Also, information from the scores or from midi signals~\cite{EwertM12} can be used to initialize the learning process. The downside of this approach is that it requires a well organized prior information that is not always available. Another approach consists in performing prior training on specific databases. A dictionary matrix $W_{train}$ can be learned from a large database in order to separate an instrument~\cite{jaureguiberry2011adaptation,wudrum}. A common method to build a dictionary for NMF is to perform a decomposition on a large training set. After the convergence, the $W$ matrix from the decomposition is used as the dictionary matrix $W_{train}$ in the separation~\cite{jaureguiberry2011adaptation}. Another method is detailed in~\cite{wudrum}, where a dictionary matrix is created by extracting template spectra from isolated drum samples. The dictionary is then used in a NMF decomposition to perform drum transcription. This method requires minimum tuning from the user. However, the dictionary should match the target instrument for satisfying performances. 

On the other hand, unsupervised algorithms rely on parametric physical models of the instruments and they count on specific constraints deduced from the characteristics of the processed signals in order to perform the decomposition. For example, harmonic instruments tend to have regular activations and are slowly varying over time so enforcing temporal smoothness improves the quality of the decomposition~\cite{Virtanen}. Similarly in~\cite{canadas2014percussive}, Canadas \& al. use four constraints to achieve a specific harmonic/percussive decomposition. The main drawback of parametrized methods is that the hyper parameters are difficult to tune, especially if the model is composed of numerous parameters. 

Concurrently, other unsupervised methods aim at underlining some mathematical properties of the decomposition, like the orthogonality between the nonnegative basis functions (or patterns). The Projective NMF (PNMF) and the Orthogonal NMF (ONMF) are typical examples of such approaches. The PNMF has been used with success in image processing~\cite{choi} for feature extraction and clustering~\cite{YangOja10}. It reveals interesting properties in practice: a higher efficiency for clustering than the NMF~\cite{choi} as well as the generation of a much sparser decomposition~\cite{YangOja10}. These inherent properties are particularly interesting for audio source separation as shown in~\cite{canadas2014percussive}. 
The main advantage of these approaches compared to other unsupervised methods is that sparsity or orthogonality are obtained as intrinsic properties, so they avoid a tedious and often unsatisfactory hyperparameter tuning stage. However, these approaches do not have a sufficient flexibility to properly represent the complexity of an audio scene composed of multiple and concurrent harmonic and percussive sources.

Using a squared Euclidean distance between the data matrix $V$ and its approximation $WH$, the NMF problem reads:
$$
\min_{W,H\geq 0} \|V - WH\|^2\ , 
$$
where $\|.\|^{2}$ is the squared Euclidean distance.

The aim of the PNMF is to find a non negative projection matrix $P \in \mathbb{R}_{+}^{n \times n}$ such that $V \approx \tilde{V} = PV$. In~\cite{yuanOja2005} Yuan \& al. propose to seek $P$ as an approximative projection matrix under the form $P = WW^{T}$ with $W \in \mathbb{R}_{+}^{n \times k}$ with $ k \leqslant n $. The PNMF problem reads : 
\begin{equation}\label{EqPnmf}
\min_{W \geqslant 0} ||V - WW^{T}V||^2 
\end{equation}

PNMF is similar to the NMF problem and can be simply obtained by replacing the activation matrix $H$ by $W^TV$. It is shown in~\cite{YangOja10} that the PNMF gives a much sparser decomposition than the NMF.

Another very similar approach is the ONMF~\cite{choi}. It consists in solving the following problem: 
\begin{align}
\min_{W \geqslant 0, H \geqslant0} ||V - WH||^2 \quad   \text{s.t}.\quad W^{T}W=I_{k} 
\end{align}%
In this method, orthogonality between nonnegative basis functions is enforced during the optimization process. In theory, it seems that the PNMF and the ONMF lead to similar decompositions, as the $W$ matrix estimated by the PNMF is almost orthogonal (i.e., $\|W^{T}W-I_{k}\|^{2}$ is small). However in practice, enforcing the orthogonality between the base at every iteration is a constraint too strong to decompose audio signal~\cite{laroche2015structured}. 

The sparsity of the dictionary matrix is an interesting property for the decomposition of audio signals and especially for the decomposition of harmonic instruments with very localized harmonic spectra. Contrary to the NMF, the sparsity of the PNMF is an inherent features of the decomposition and contrary to a regularization term, there is no hyper parameter tuning. These key properties of the PNMF motivated us to decompose the harmonic instruments using orthogonal basis functions.




\subsection{Harmonic/Percussive Source Separation}


The most used HPSS method consists in applying a Median Filtering (MF) on the spectrogram of the audio signal~\cite{fitzgerald2010harmonic}. The filtering is made across the temporal atoms to diminish the transient sounds in order to extract the harmonic components. Mutually, the filtering is made across frequency to reduce the harmonic tonal sounds and to enhance the percussive instruments. The assumption made is that the harmonics are considered to be outliers in a temporal frame that contains a mixture of percussive and pitched instruments. Similarly, the percussive onsets are considered to be outliers in a frequency frame. This method is often used in the \emph{Music Information Retrieval} community as it requires few parameter tuning and is computationally effective. We compare our method to the MF as it is the most popular method for a HPSS preprocessing.

Another unsupervised method uses a Non negative Matrix Factorization (NMF) decomposition with specific constraints to distinguish the harmonic part from the percussive components~\cite{canadas2014percussive}. A frequency regularity and a temporal sparsity constraints are applied during the optimization process to extract the percussive instruments and vice-versa a temporal regularity and a frequency sparsity constraints are applied to extract the harmonic instruments. Let consider the magnitude spectrogram $V$ composed of $T$ frames, $F$ frequency bins, the model is written as follow:
$$ V_{FT} \approx V_p + V_H = W_{P_{F,R_p}} H_{P_{F,R_p}} + W_{H_{F,R_h}} H_{H_{F,R_h}} $$
were the parameter $R_h$ and $R_p$ denote the number of harmonic and percussive components respectively. The harmonic sounds are modelled by assuming smoothness in time and sparseness in frequency. The Temporal Smoothness (TSM) is defined as follow 
\begin{equation}\label{TSM}
TSM = \frac{F}{R_h} \sum_{r_h=1}^{R_h}\frac{1}{\sigma_{H_{H_{r_h}}}^2} \sum_{t=2}^{T}(H_{H_{r_h,t-1}} - H_{H_{r_h,t}})^2
\end{equation}
The value $\sigma_{H_{H}} = \sqrt{\frac{1}{T} \sum_{t=1}^{T} H_{H_{r_h,t}}^2 }$ is a normalization term to make the global objective function independent to the norm of the signal. Spectral Sparseness (SSP) is designed using the same constrain as in \cite{Virtanen}:
\begin{equation}\label{SSP}
SSP = \frac{T}{R_h} \sum_{r_h=1}^{R_h}\sum_{f=1}^{F} \mid\frac{W_{H_{f,r_h}}}{\sigma_{W_{H_{r_h}}}}\mid
\end{equation}
with $\sigma = \sqrt{\frac{1}{F} \sum_{f=1}^{F} W_{H_{f,r_h}}^2 }$.
Similarly, for the percussive part, the authors used a constrain of Temporal Sparseness (TSP) on the activation matrix, and a constrain of Spectral Smoothness (SSM) on the dictionary matrix. 
This method gives good results compared to other state-of-the-art methods but this article will show that the results depend heavily on the training database. We compare our method to the CoNMF has it is the most recent method available for HPSS.

Finally, a supervised method uses a Non-Negative Matrix Partial Co-Factorization (NMPCF)~\cite{kim2011nonnegative} to extract the drums. The spectrogram of the signal and the drum-only data (obtained from prior learning) are simultaneously decomposed in order to determine common basis vectors that capture the spectral and temporal characteristics of drum sources. The shared dictionary matrix retrieves the drum signal. However it must be chosen carefully in order to obtain satisfying results. The percussive part of the decomposition is constrained while the harmonic part is completely unconstrained. As a result, it tends to decompose a lot of information (i.e., the harmonic part contains some percussive instruments) from the signal and the decomposition is not satisfactory. The NMPCF is a recent supervised method and it is a good benchmark for our comparison.

